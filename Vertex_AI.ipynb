{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vertex-AI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ze4-nDLfK4pw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojashreeNS/Vertex_AI/blob/main/Vertex_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "### Install additional packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "source": [
        "import os\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyy5Lbnzg5fi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8ce8e18-9bf1-49b8-89c5-d7f5f370a835"
      },
      "source": [
        "! pip install {USER_FLAG} --upgrade git+https://github.com/googleapis/python-aiplatform.git@v1.6.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/googleapis/python-aiplatform.git@v1.6.0\n",
            "  Cloning https://github.com/googleapis/python-aiplatform.git (to revision v1.6.0) to /tmp/pip-req-build-wt6xdko_\n",
            "  Running command git clone -q https://github.com/googleapis/python-aiplatform.git /tmp/pip-req-build-wt6xdko_\n",
            "  Running command git checkout -q 293809edba6bd9275f9be047b4bdd33da17f025f\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.6.0) (1.26.3)\n",
            "Collecting proto-plus>=1.10.1\n",
            "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.6.0) (21.3)\n",
            "Collecting google-cloud-storage<2.0.0dev,>=1.32.0\n",
            "  Downloading google_cloud_storage-1.43.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.6.0) (1.21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (1.42.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.6.0) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.6.0) (0.4.1)\n",
            "  Downloading google_cloud_storage-1.42.3-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 79.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.2-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 68.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 63.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.0-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 72.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.41.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 46.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.41.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 69.5 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.40.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 71.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.39.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 72.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.38.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 71.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.37.1-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 68.5 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.37.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 69.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.8 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.1-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.35.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.35.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.34.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.0.3\n",
            "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
            "Collecting google-cloud-storage<2.0.0dev,>=1.32.0\n",
            "  Downloading google_cloud_storage-1.33.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 9.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.32.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 10.0 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-core<2.0dev,>=1.0.3\n",
            "  Downloading google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.7.0-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.5.0-py2.py3-none-any.whl (27 kB)\n",
            "  Downloading google_cloud_core-1.4.4-py2.py3-none-any.whl (27 kB)\n",
            "  Downloading google_cloud_core-1.4.3-py2.py3-none-any.whl (27 kB)\n",
            "INFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_cloud_core-1.4.2-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.4.1-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.4.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.2.0-py2.py3-none-any.whl (26 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "  Downloading google_cloud_core-1.1.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.0.3-py2.py3-none-any.whl (26 kB)\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
            "  Downloading google_cloud_bigquery-2.31.0-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.6.0) (2.8.2)\n",
            "Collecting google-cloud-core<3.0.0dev,>=1.4.1\n",
            "  Downloading google_cloud_core-2.2.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-2.1.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
            "  Downloading google_cloud_bigquery-2.30.1-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 73.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.30.0-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 70.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.29.0-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 62.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.28.1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 66.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.28.0-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 71.3 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.27.1-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 70.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.27.0-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 71.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.26.0-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 67.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.25.2-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 69.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.25.1-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 66.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.25.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 63.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.24.1-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 60.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.24.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 70.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.23.3-py2.py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 84.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.23.2-py2.py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 73.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.23.1-py2.py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 68.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.23.0-py2.py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 67.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.22.1-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 67.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.22.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[K     |████████████████████████████████| 194 kB 61.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.21.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 65.8 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.20.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 54.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.19.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 69.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_bigquery-2.18.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting google-resumable-media<2.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-1.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform==1.6.0) (3.0.6)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.6.0) (3.0.4)\n",
            "Building wheels for collected packages: google-cloud-aiplatform\n",
            "  Building wheel for google-cloud-aiplatform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-cloud-aiplatform: filename=google_cloud_aiplatform-1.6.0-py2.py3-none-any.whl size=1583132 sha256=bc46ce59c873acd14c544b3d711bf267129c4db21d9ef43313b375239b9b6f1c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u8s5iv4u/wheels/15/bb/3d/3208e2de579393bf28fb2844994eb7918ac74f3848115d5607\n",
            "Successfully built google-cloud-aiplatform\n",
            "Installing collected packages: protobuf, google-crc32c, proto-plus, google-resumable-media, google-cloud-core, google-cloud-storage, google-cloud-bigquery, google-cloud-aiplatform\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 1.21.0\n",
            "    Uninstalling google-cloud-bigquery-1.21.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.18.0 which is incompatible.\u001b[0m\n",
            "Successfully installed google-cloud-aiplatform-1.6.0 google-cloud-bigquery-2.18.0 google-cloud-core-1.7.2 google-cloud-storage-1.41.1 google-crc32c-1.3.0 google-resumable-media-1.3.3 proto-plus-1.19.8 protobuf-3.19.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhq5zEbGg0XX"
      },
      "source": [
        "### Restart the kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrelQZ22IZj"
      },
      "source": [
        "# Automatically restart kernel after installs\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Automatically restart kernel after installs\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "# Get your Google Cloud project ID from gcloud\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJYoRfYng0XZ"
      },
      "source": [
        "Otherwise, set your project ID here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riG_qUokg0XZ"
      },
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"vertexassignment\"  # @param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-9euPZ17kA",
        "outputId": "6a4157c9-ec3e-4eb0-fcb2-91706f995dc5"
      },
      "source": [
        "print(PROJECT_ID)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vertexassignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# If on Google Cloud Notebooks, then don't execute this code\n",
        "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAL9Y4VTOLT1"
      },
      "source": [
        "## Prepare for output\n",
        "\n",
        "### Step 1. Create dataset for output\n",
        "\n",
        "We need a BigQuery dataset to host the output data in `us-central1`. Input the name of the dataset you want to created and specify the name of the table you want to store the output later. These will be used later in the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oc-jrd6Ow7N"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "from google.cloud import bigquery"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOaGi2PrEAwA"
      },
      "source": [
        "# Output dataset\n",
        "DESTINATION_DATA_SET = \"movie_predictions\"  # @param {type:\"string\"}\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "DESTINATION_DATA_SET = \"{prefix}_{timestamp}\".format(\n",
        "    prefix=DESTINATION_DATA_SET, timestamp=TIMESTAMP\n",
        ")\n",
        "\n",
        "# Output table. Make sure that the table does NOT already exist; the BatchReadFeatureValues API cannot overwrite an existing table\n",
        "DESTINATION_TABLE_NAME = \"training_data\"  # @param {type:\"string\"}\n",
        "\n",
        "DESTINATION_PATTERN = \"bq://{project}.{dataset}.{table}\"\n",
        "DESTINATION_TABLE_URI = DESTINATION_PATTERN.format(\n",
        "    project=PROJECT_ID, dataset=DESTINATION_DATA_SET, table=DESTINATION_TABLE_NAME\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKhmymT-O0vy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17630e88-46e1-4327-be4c-81860ede246b"
      },
      "source": [
        "# Create dataset\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "dataset_id = \"{}.{}\".format(client.project, DESTINATION_DATA_SET)\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "dataset.location = REGION\n",
        "dataset = client.create_dataset(dataset)\n",
        "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset vertexassignment.movie_predictions_20211211035834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEqT2Y4DJmf"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isNzmylQXjly"
      },
      "source": [
        "# Other than project ID and featurestore ID and endpoints needs to be set\n",
        "API_ENDPOINT = \"us-central1-aiplatform.googleapis.com\"  # @param {type:\"string\"}\n",
        "INPUT_CSV_FILE = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRUOFELefqf1"
      },
      "source": [
        "from google.cloud.aiplatform_v1 import (FeaturestoreOnlineServingServiceClient,\n",
        "                                        FeaturestoreServiceClient)\n",
        "from google.cloud.aiplatform_v1.types import FeatureSelector, IdMatcher\n",
        "from google.cloud.aiplatform_v1.types import entity_type as entity_type_pb2\n",
        "from google.cloud.aiplatform_v1.types import feature as feature_pb2\n",
        "from google.cloud.aiplatform_v1.types import featurestore as featurestore_pb2\n",
        "from google.cloud.aiplatform_v1.types import \\\n",
        "    featurestore_online_service as featurestore_online_service_pb2\n",
        "from google.cloud.aiplatform_v1.types import \\\n",
        "    featurestore_service as featurestore_service_pb2\n",
        "from google.cloud.aiplatform_v1.types import io as io_pb2\n",
        "from google.protobuf.duration_pb2 import Duration\n",
        "\n",
        "# Create admin_client for CRUD and data_client for reading feature values.\n",
        "admin_client = FeaturestoreServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
        "data_client = FeaturestoreOnlineServingServiceClient(\n",
        "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
        ")\n",
        "\n",
        "# Represents featurestore resource path.\n",
        "BASE_RESOURCE_PATH = admin_client.common_location_path(PROJECT_ID, REGION)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buQBIv3ZL3A0"
      },
      "source": [
        "### Create Featurestore\n",
        "\n",
        "The method to create a featurestore returns a\n",
        "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API\n",
        "methods too, such as updating or deleting a featurestore. Calling\n",
        "`create_fs_lro.result()` waits for the LRO to complete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FscHZa0DXjmC"
      },
      "source": [
        "FEATURESTORE_ID = \"movie_prediction\"\n",
        "create_lro = admin_client.create_featurestore(\n",
        "    featurestore_service_pb2.CreateFeaturestoreRequest(\n",
        "        parent=BASE_RESOURCE_PATH,\n",
        "        featurestore_id=FEATURESTORE_ID,\n",
        "        featurestore=featurestore_pb2.Featurestore(\n",
        "            online_serving_config=featurestore_pb2.Featurestore.OnlineServingConfig(\n",
        "                fixed_node_count=1\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57V8eVcB5VFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49e78ef-5f8a-41d8-ce69-42c9df1e12d6"
      },
      "source": [
        "# Wait for LRO to finish and get the LRO result.\n",
        "print(create_lro.result())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhD4q8rXjmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8beadc36-7d65-4158-ff8b-78b4cd324868"
      },
      "source": [
        "admin_client.get_featurestore(\n",
        "    name=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID)\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction\"\n",
              "create_time {\n",
              "  seconds: 1639195358\n",
              "  nanos: 135658000\n",
              "}\n",
              "update_time {\n",
              "  seconds: 1639195358\n",
              "  nanos: 279282000\n",
              "}\n",
              "etag: \"AMEw9yORJHl-GH_pXmF5oEQsH_oL0Cnvyzjl0IjwGUmlBPepMKDu7bI_KW5q2zB3DRBj\"\n",
              "online_serving_config {\n",
              "  fixed_node_count: 1\n",
              "}\n",
              "state: STABLE"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmJq75zXjmT"
      },
      "source": [
        "### Create Entity Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9eZ7aJLXjmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908155dd-72df-466a-8d07-7e482e2b8bd9"
      },
      "source": [
        "users_entity_type_lro = admin_client.create_entity_type(\n",
        "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
        "        parent=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
        "        entity_type_id=\"users\",\n",
        "        entity_type=entity_type_pb2.EntityType(\n",
        "            description=\"Users entity\",\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Similarly, wait for EntityType creation operation.\n",
        "print(users_entity_type_lro.result())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJqNOttvOc2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c929b93-9934-4807-d187-83f834dc2949"
      },
      "source": [
        "# Create movies entity type without a monitoring configuration.\n",
        "movies_entity_type_lro = admin_client.create_entity_type(\n",
        "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
        "        parent=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
        "        entity_type_id=\"movies\",\n",
        "        entity_type=entity_type_pb2.EntityType(description=\"Movies entity\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Similarly, wait for EntityType creation operation.\n",
        "print(movies_entity_type_lro.result())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85b1f59fbf6d"
      },
      "source": [
        "Feature [monitoring](https://cloud.google.com/vertex-ai/docs/featurestore/monitoring) is in preview, we need to use v1beta1 Python. The easiest way to set this for now is using [console UI](https://console.cloud.google.com/vertex-ai/features).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0852e5f7d49b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480c5c60-5d03-48ec-84e2-b5de4fb4af09"
      },
      "source": [
        "from google.cloud.aiplatform_v1beta1 import \\\n",
        "    FeaturestoreServiceClient as v1beta1_FeaturestoreServiceClient\n",
        "from google.cloud.aiplatform_v1beta1.types import \\\n",
        "    entity_type as v1beta1_entity_type_pb2\n",
        "from google.cloud.aiplatform_v1beta1.types import \\\n",
        "    featurestore_monitoring as v1beta1_featurestore_monitoring_pb2\n",
        "from google.cloud.aiplatform_v1beta1.types import \\\n",
        "    featurestore_service as v1beta1_featurestore_service_pb2\n",
        "\n",
        "v1beta1_admin_client = v1beta1_FeaturestoreServiceClient(\n",
        "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
        ")\n",
        "\n",
        "# Enable monitoring for users entity type.\n",
        "# All Features belonging to this EntityType will by default inherit the monitoring config.\n",
        "v1beta1_admin_client.update_entity_type(\n",
        "    v1beta1_featurestore_service_pb2.UpdateEntityTypeRequest(\n",
        "        entity_type=v1beta1_entity_type_pb2.EntityType(\n",
        "            name=admin_client.entity_type_path(\n",
        "                PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
        "            ),\n",
        "            monitoring_config=v1beta1_featurestore_monitoring_pb2.FeaturestoreMonitoringConfig(\n",
        "                snapshot_analysis=v1beta1_featurestore_monitoring_pb2.FeaturestoreMonitoringConfig.SnapshotAnalysis(\n",
        "                    monitoring_interval=Duration(seconds=86400),  # 1 day\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
              "description: \"Users entity\"\n",
              "create_time {\n",
              "  seconds: 1639195417\n",
              "  nanos: 759429000\n",
              "}\n",
              "update_time {\n",
              "  seconds: 1639195429\n",
              "  nanos: 944245000\n",
              "}\n",
              "etag: \"AMEw9yO6Vok0XEML4Ku9BvrqRXIIq3uEnBpeaQ5Wc6Y3gxTFAm0k-8SMSgtcUhSIlZqP\"\n",
              "monitoring_config {\n",
              "  snapshot_analysis {\n",
              "    monitoring_interval {\n",
              "      seconds: 86400\n",
              "    }\n",
              "    monitoring_interval_days: 1\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJW4q-0jO2Xf"
      },
      "source": [
        "### Create Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJD7-6GFqc1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59136eb-4f8d-43e7-813d-5955ee0c76c5"
      },
      "source": [
        "# Create features for the 'users' entity.\n",
        "admin_client.batch_create_features(\n",
        "    parent=admin_client.entity_type_path(PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"),\n",
        "    requests=[\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.INT64,\n",
        "                description=\"User age\",\n",
        "            ),\n",
        "            feature_id=\"age\",\n",
        "        ),\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
        "                description=\"User gender\",\n",
        "            ),\n",
        "            feature_id=\"gender\",\n",
        "        ),\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.STRING_ARRAY,\n",
        "                description=\"An array of genres that this user liked\",\n",
        "            ),\n",
        "            feature_id=\"liked_genres\",\n",
        "        ),\n",
        "    ],\n",
        ").result()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/age\"\n",
              "}\n",
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/gender\"\n",
              "}\n",
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/liked_genres\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWx_wI_FS8tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44af8963-1a69-494c-ee87-776887c8b09a"
      },
      "source": [
        "# Create features for movies type.\n",
        "# 'title' Feature enables monitoring.\n",
        "admin_client.batch_create_features(\n",
        "    parent=admin_client.entity_type_path(PROJECT_ID, REGION, FEATURESTORE_ID, \"movies\"),\n",
        "    requests=[\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
        "                description=\"The title of the movie\",\n",
        "            ),\n",
        "            feature_id=\"title\",\n",
        "        ),\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
        "                description=\"The genres of the movie\",\n",
        "            ),\n",
        "            feature_id=\"genres\",\n",
        "        ),\n",
        "        featurestore_service_pb2.CreateFeatureRequest(\n",
        "            feature=feature_pb2.Feature(\n",
        "                value_type=feature_pb2.Feature.ValueType.DOUBLE,\n",
        "                description=\"The average rating for the movie, range is [1.0-5.0]\",\n",
        "            ),\n",
        "            feature_id=\"average_rating\",\n",
        "        ),\n",
        "    ],\n",
        ").result()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
              "}\n",
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/genres\"\n",
              "}\n",
              "features {\n",
              "  name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUVOzrAb1AFX"
      },
      "source": [
        "## Search created features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs_7T_hs17ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8888695f-25dc-4a7d-e2fd-97fed824e0a9"
      },
      "source": [
        "# Search for all features across all featurestores.\n",
        "list(admin_client.search_features(location=BASE_RESOURCE_PATH))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
              " description: \"The average rating for the movie, range is [1.0-5.0]\"\n",
              " value_type: DOUBLE\n",
              " create_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 595768000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 595768000\n",
              " },\n",
              " name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/genres\"\n",
              " description: \"The genres of the movie\"\n",
              " value_type: STRING\n",
              " create_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 594609000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 594609000\n",
              " },\n",
              " name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
              " description: \"The title of the movie\"\n",
              " value_type: STRING\n",
              " create_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 593528000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 593528000\n",
              " },\n",
              " name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/age\"\n",
              " description: \"User age\"\n",
              " value_type: INT64\n",
              " create_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 141825000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 141825000\n",
              " },\n",
              " name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/gender\"\n",
              " description: \"User gender\"\n",
              " value_type: STRING\n",
              " create_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 143537000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 143537000\n",
              " },\n",
              " name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/liked_genres\"\n",
              " description: \"An array of genres that this user liked\"\n",
              " value_type: STRING_ARRAY\n",
              " create_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 144882000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195437\n",
              "   nanos: 144882000\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcxsiBUiIyvE"
      },
      "source": [
        "Now, narrow down the search to features that are of type `DOUBLE`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9ovJSyEI4OZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad3a7b4-c720-4d4d-e260-ed0332928d8f"
      },
      "source": [
        "# Search for all features with value type `DOUBLE`\n",
        "list(\n",
        "    admin_client.search_features(\n",
        "        featurestore_service_pb2.SearchFeaturesRequest(\n",
        "            location=BASE_RESOURCE_PATH, query=\"value_type=DOUBLE\"\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
              " description: \"The average rating for the movie, range is [1.0-5.0]\"\n",
              " value_type: DOUBLE\n",
              " create_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 595768000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 595768000\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtr9tvH6JAOY"
      },
      "source": [
        "Or, limit the search results to features with specific keywords in their ID and type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G1mNV1uJFBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a7da5e-8c45-400f-ce6a-16e9d22deb5d"
      },
      "source": [
        "# Filter on feature value type and keywords.\n",
        "list(\n",
        "    admin_client.search_features(\n",
        "        featurestore_service_pb2.SearchFeaturesRequest(\n",
        "            location=BASE_RESOURCE_PATH, query=\"feature_id:title AND value_type=STRING\"\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
              " description: \"The title of the movie\"\n",
              " value_type: STRING\n",
              " create_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 593528000\n",
              " }\n",
              " update_time {\n",
              "   seconds: 1639195443\n",
              "   nanos: 593528000\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7DyDa6chbJx"
      },
      "source": [
        "### Import feature values for Users\n",
        "\n",
        "When importing, specify the following in your request:\n",
        "\n",
        "*   Data source format: BigQuery Table/Avro/CSV\n",
        "*   Data source URL\n",
        "*   Destination: featurestore/entity types/features to be imported\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUhm6-yzXjmx"
      },
      "source": [
        "import_users_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
        "    entity_type=admin_client.entity_type_path(\n",
        "        PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
        "    ),\n",
        "    avro_source=io_pb2.AvroSource(\n",
        "        # Source\n",
        "        gcs_source=io_pb2.GcsSource(\n",
        "            uris=[\n",
        "                \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
        "            ]\n",
        "        )\n",
        "    ),\n",
        "    entity_id_field=\"user_id\",\n",
        "    feature_specs=[\n",
        "        # Features\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"age\"),\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"gender\"),\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
        "            id=\"liked_genres\"\n",
        "        ),\n",
        "    ],\n",
        "    feature_time_field=\"update_time\",\n",
        "    worker_count=1,\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwznuUiwjwJF"
      },
      "source": [
        "# Start to import, will take a couple of minutes\n",
        "ingestion_lro = admin_client.import_feature_values(import_users_request)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDl3ZcrF64T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c42c46-320f-452a-e871-23ff20fec634"
      },
      "source": [
        "# Polls for the LRO status and prints when the LRO has completed\n",
        "ingestion_lro.result()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "imported_entity_count: 7\n",
              "imported_feature_value_count: 12"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laXdJPIqkLJO"
      },
      "source": [
        "### Import feature values for Movies\n",
        "\n",
        "Similarly, import feature values for 'movies' into the featurestore.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W1lCxgDl6iR"
      },
      "source": [
        "import_movie_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
        "    entity_type=admin_client.entity_type_path(\n",
        "        PROJECT_ID, REGION, FEATURESTORE_ID, \"movies\"\n",
        "    ),\n",
        "    avro_source=io_pb2.AvroSource(\n",
        "        gcs_source=io_pb2.GcsSource(\n",
        "            uris=[\n",
        "                \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
        "            ]\n",
        "        )\n",
        "    ),\n",
        "    entity_id_field=\"movie_id\",\n",
        "    feature_specs=[\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"title\"),\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"genres\"),\n",
        "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
        "            id=\"average_rating\"\n",
        "        ),\n",
        "    ],\n",
        "    feature_time_field=\"update_time\",\n",
        "    worker_count=1,\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-MATtpvm3HI"
      },
      "source": [
        "# Start to import, will take a couple of minutes\n",
        "ingestion_lro = admin_client.import_feature_values(import_movie_request)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpaK3yRCnNnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7156608b-1105-4cc9-94a6-c5a13ab9f1c8"
      },
      "source": [
        "# Polls for the LRO status and prints when the LRO has completed\n",
        "ingestion_lro.result()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "imported_entity_count: 4\n",
              "imported_feature_value_count: 12"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TdxPYdDXjnA"
      },
      "source": [
        "## Online serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezJIMyU-XjnB"
      },
      "source": [
        "The\n",
        "[Online Serving APIs](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestoreonlineservingservice)\n",
        "lets you serve feature values for small batches of entities. It's designed for latency-sensitive service, such as online model prediction. For example, for a movie service, we might want to quickly shows movies that the current user would most likely watch by using online predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foNB0D2aw37c"
      },
      "source": [
        "### Read one entity per request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rfWqLrbXjnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c48c12-357c-4b32-8ef9-4e8fcd38c100"
      },
      "source": [
        "# Fetch the following 3 features.\n",
        "feature_selector = FeatureSelector(\n",
        "    id_matcher=IdMatcher(ids=[\"age\", \"gender\", \"liked_genres\"])\n",
        ")\n",
        "\n",
        "data_client.read_feature_values(\n",
        "    featurestore_online_service_pb2.ReadFeatureValuesRequest(\n",
        "        # Fetch from the following feature store/entity type\n",
        "        entity_type=admin_client.entity_type_path(\n",
        "            PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
        "        ),\n",
        "        # Fetch the user features whose ID is \"alice\"\n",
        "        entity_id=\"alice\",\n",
        "        feature_selector=feature_selector,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "header {\n",
              "  entity_type: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
              "  feature_descriptors {\n",
              "    id: \"age\"\n",
              "  }\n",
              "  feature_descriptors {\n",
              "    id: \"gender\"\n",
              "  }\n",
              "  feature_descriptors {\n",
              "    id: \"liked_genres\"\n",
              "  }\n",
              "}\n",
              "entity_view {\n",
              "  entity_id: \"alice\"\n",
              "  data {\n",
              "    value {\n",
              "      int64_value: 55\n",
              "      metadata {\n",
              "        generate_time {\n",
              "          seconds: 1629493102\n",
              "          nanos: 261000000\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  data {\n",
              "    value {\n",
              "      string_value: \"Female\"\n",
              "      metadata {\n",
              "        generate_time {\n",
              "          seconds: 1629493102\n",
              "          nanos: 261000000\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  data {\n",
              "    value {\n",
              "      string_array_value {\n",
              "        values: \"Drama\"\n",
              "      }\n",
              "      metadata {\n",
              "        generate_time {\n",
              "          seconds: 1629493102\n",
              "          nanos: 261000000\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYk83Zt9xF8m"
      },
      "source": [
        "### Read multiple entities per request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIJFcIIHULOd"
      },
      "source": [
        "# Read the same set of features as above, but for multiple entities.\n",
        "response_stream = data_client.streaming_read_feature_values(\n",
        "    featurestore_online_service_pb2.StreamingReadFeatureValuesRequest(\n",
        "        entity_type=admin_client.entity_type_path(\n",
        "            PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
        "        ),\n",
        "        entity_ids=[\"alice\", \"bob\"],\n",
        "        feature_selector=feature_selector,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFrVLiHyUj2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093c37b2-a4b8-42ed-dd09-cede86e6d5ca"
      },
      "source": [
        "# Iterate and process response. Note the first one is always the header only.\n",
        "for response in response_stream:\n",
        "    print(response)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "header {\n",
            "  entity_type: \"projects/451795182630/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
            "  feature_descriptors {\n",
            "    id: \"age\"\n",
            "  }\n",
            "  feature_descriptors {\n",
            "    id: \"gender\"\n",
            "  }\n",
            "  feature_descriptors {\n",
            "    id: \"liked_genres\"\n",
            "  }\n",
            "}\n",
            "\n",
            "entity_view {\n",
            "  entity_id: \"alice\"\n",
            "  data {\n",
            "    value {\n",
            "      int64_value: 55\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  data {\n",
            "    value {\n",
            "      string_value: \"Female\"\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  data {\n",
            "    value {\n",
            "      string_array_value {\n",
            "        values: \"Drama\"\n",
            "      }\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "entity_view {\n",
            "  entity_id: \"bob\"\n",
            "  data {\n",
            "    value {\n",
            "      int64_value: 35\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  data {\n",
            "    value {\n",
            "      string_value: \"Male\"\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  data {\n",
            "    value {\n",
            "      string_array_value {\n",
            "        values: \"Action\"\n",
            "        values: \"Adventure\"\n",
            "      }\n",
            "      metadata {\n",
            "        generate_time {\n",
            "          seconds: 1629493102\n",
            "          nanos: 261000000\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8dLJ9nuDFgI"
      },
      "source": [
        "### Batch Read Feature Values\n",
        "\n",
        "Assemble the request which specify the following info:\n",
        "\n",
        "*   Where is the label data, i.e., Table 1.\n",
        "*   Which features are read, i.e., the column names in Table 2.\n",
        "\n",
        "The output is stored in a BigQuery table.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyoXHY2ECnh"
      },
      "source": [
        "batch_serving_request = featurestore_service_pb2.BatchReadFeatureValuesRequest(\n",
        "    # featurestore info\n",
        "    featurestore=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
        "    # URL for the label data, i.e., Table 1.\n",
        "    csv_read_instances=io_pb2.CsvSource(\n",
        "        gcs_source=io_pb2.GcsSource(uris=[INPUT_CSV_FILE])\n",
        "    ),\n",
        "    destination=featurestore_service_pb2.FeatureValueDestination(\n",
        "        bigquery_destination=io_pb2.BigQueryDestination(\n",
        "            # Output to BigQuery table created earlier\n",
        "            output_uri=DESTINATION_TABLE_URI\n",
        "        )\n",
        "    ),\n",
        "    entity_type_specs=[\n",
        "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
        "            # Read the 'age', 'gender' and 'liked_genres' features from the 'users' entity\n",
        "            entity_type_id=\"users\",\n",
        "            feature_selector=FeatureSelector(\n",
        "                id_matcher=IdMatcher(\n",
        "                    ids=[\n",
        "                        # features, use \"*\" if you want to select all features within this entity type\n",
        "                        \"age\",\n",
        "                        \"gender\",\n",
        "                        \"liked_genres\",\n",
        "                    ]\n",
        "                )\n",
        "            ),\n",
        "        ),\n",
        "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
        "            # Read the 'average_rating' and 'genres' feature values of the 'movies' entity\n",
        "            entity_type_id=\"movies\",\n",
        "            feature_selector=FeatureSelector(\n",
        "                id_matcher=IdMatcher(ids=[\"average_rating\", \"genres\"])\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZO5sRCfEEWn"
      },
      "source": [
        "# Execute the batch read\n",
        "batch_serving_lro = admin_client.batch_read_feature_values(batch_serving_request)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouMiJqh-EFlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e54b86-63a1-4743-acbf-8777fcb35bec"
      },
      "source": [
        "# This long runing operation will poll until the batch read finishes.\n",
        "batch_serving_lro.result()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, we can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2WfqhbFzQBF"
      },
      "source": [
        "admin_client.delete_featurestore(\n",
        "    request=featurestore_service_pb2.DeleteFeaturestoreRequest(\n",
        "        name=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
        "        force=True,\n",
        "    )\n",
        ").result()\n",
        "client.delete_dataset(\n",
        "    DESTINATION_DATA_SET, delete_contents=True, not_found_ok=True\n",
        ")  # Make an API request.\n",
        "\n",
        "print(\"Deleted dataset '{}'.\".format(DESTINATION_DATA_SET))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}