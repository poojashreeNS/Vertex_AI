{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-classification-gcp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrKxEIy+kk01MNtv8jHrVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojashreeNS/Vertex_AI/blob/main/Text_classification_gcp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OP59Taqu0jmI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\"\n",
        "\n",
        "! pip install {USER_FLAG} --upgrade google-cloud-aiplatform google-cloud-storage jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"\"\n",
        "\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Get your Google Cloud project ID from gcloud\n",
        "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
        "    PROJECT_ID = shell_output[0]\n",
        "    print(\"Project ID: \", PROJECT_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOkvfpVa0lPG",
        "outputId": "250d9328-5c5a-4b71-a661-d0c2b684787f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project ID:  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if PROJECT_ID == \"\" or PROJECT_ID is None:\n",
        "    PROJECT_ID = \"vertexaiprediction\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "BBdTM49W0qtG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "import jsonlines\n",
        "from google.cloud import aiplatform, storage\n",
        "from google.protobuf import json_format\n",
        "\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "# If you are running this notebook in Colab, run this cell and follow the\n",
        "# instructions to authenticate your GCP account. This provides access to your\n",
        "# Cloud Storage bucket and lets you submit training jobs and prediction\n",
        "# requests.\n",
        "\n",
        "# If on Google Cloud Notebooks, then don't execute this code\n",
        "if not IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth as google_auth\n",
        "\n",
        "        google_auth.authenticate_user()\n",
        "\n",
        "    # If you are running this notebook locally, replace the string below with the\n",
        "    # path to your service account key and run this cell to authenticate your GCP\n",
        "    # account.\n",
        "    elif not os.getenv(\"IS_TESTING\"):\n",
        "        %env GOOGLE_APPLICATION_CREDENTIALS ''\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "ZFjsQElD0uma"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a dataset and import your data**"
      ],
      "metadata": {
        "id": "HinG_i0m08S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a timestamp to ensure unique resources\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "src_uris = \"gs://cloud-ml-data/NL-classification/happiness.csv\"\n",
        "display_name = f\"e2e-text-dataset-{TIMESTAMP}\""
      ],
      "metadata": {
        "id": "zgLgVxYN092t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = aiplatform.TextDataset.create(\n",
        "    display_name=display_name,\n",
        "    gcs_source=src_uris,\n",
        "    import_schema_uri=aiplatform.schema.dataset.ioformat.text.single_label_classification,\n",
        "    sync=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njIbTcoQ1BKV",
        "outputId": "f2107075-af09-4593-a52d-00f3811525b0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.datasets.dataset:Creating TextDataset\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:Create TextDataset backing LRO: projects/63364166818/locations/us-central1/datasets/7344517771218124800/operations/2276863249959878656\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:TextDataset created. Resource name: projects/63364166818/locations/us-central1/datasets/7344517771218124800\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:To use this TextDataset in another session:\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.TextDataset('projects/63364166818/locations/us-central1/datasets/7344517771218124800')\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:Importing TextDataset data: projects/63364166818/locations/us-central1/datasets/7344517771218124800\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:Import TextDataset data backing LRO: projects/63364166818/locations/us-central1/datasets/7344517771218124800/operations/4024259905379631104\n",
            "INFO:google.cloud.aiplatform.datasets.dataset:TextDataset data imported. Resource name: projects/63364166818/locations/us-central1/datasets/7344517771218124800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train your text classification model**"
      ],
      "metadata": {
        "id": "c8IlXf_K1Gey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = aiplatform.TextDataset.list(filter=f'display_name=\"{display_name}\"')\n",
        "print(datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79JAJvy71Ema",
        "outputId": "b0c7c180-3a54-4488-bef2-5292efcecad9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<google.cloud.aiplatform.datasets.text_dataset.TextDataset object at 0x7f89161383d0> \n",
            "resource name: projects/63364166818/locations/us-central1/datasets/7344517771218124800]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset ID if it's not available\n",
        "dataset_id = \"[your-dataset-id]\"\n",
        "\n",
        "if dataset_id == \"[your-dataset-id]\":\n",
        "    # Use the reference to the new dataset captured when we created it\n",
        "    dataset_id = ds.resource_name.split(\"/\")[-1]\n",
        "    print(f\"Dataset ID: {dataset_id}\")\n",
        "\n",
        "text_dataset = aiplatform.TextDataset(dataset_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ITe2QUN1KzU",
        "outputId": "0fc08da5-7f62-4b52-cbc0-0d7dfd42f364"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ID: 7344517771218124800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training job\n",
        "training_job_display_name = f\"e2e-text-training-job-{TIMESTAMP}\"\n",
        "job = aiplatform.AutoMLTextTrainingJob(\n",
        "    display_name=training_job_display_name,\n",
        "    prediction_type=\"classification\",\n",
        "    multi_label=False,\n",
        ")"
      ],
      "metadata": {
        "id": "D3obZgfG1N2d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_display_name = f\"e2e-text-classification-model-{TIMESTAMP}\"\n",
        "\n",
        "# Run the training job\n",
        "model = job.run(\n",
        "    dataset=text_dataset,\n",
        "    model_display_name=model_display_name,\n",
        "    training_fraction_split=0.7,\n",
        "    validation_fraction_split=0.2,\n",
        "    test_fraction_split=0.1,\n",
        "    sync=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YKbUtBiV1Q8z",
        "outputId": "2bf9550e-8778-4a26-dbc8-c1a2c43b8b7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/9210759538972557312?project=63364166818\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "INFO:google.cloud.aiplatform.training_jobs:AutoMLTextTrainingJob projects/63364166818/locations/us-central1/trainingPipelines/9210759538972557312 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8756d6e51acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_fraction_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_fraction_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, model_display_name, model_labels, sync)\u001b[0m\n\u001b[1;32m   6508\u001b[0m             \u001b[0mmodel_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_display_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6509\u001b[0m             \u001b[0mmodel_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6510\u001b[0;31m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6511\u001b[0m         )\n\u001b[1;32m   6512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, model_display_name, model_labels, sync)\u001b[0m\n\u001b[1;32m   6627\u001b[0m             \u001b[0mvalidation_filter_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_filter_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6628\u001b[0m             \u001b[0mtest_filter_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_filter_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6629\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6630\u001b[0m         )\n\u001b[1;32m   6631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_run_job\u001b[0;34m(self, training_task_definition, training_task_inputs, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, annotation_schema_uri, model, gcs_destination_uri_prefix, bigquery_destination)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"View Training:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashboard_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_get_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m--> 838\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_failed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/aiplatform/training_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get and review model evaluation scores**"
      ],
      "metadata": {
        "id": "kd3d4r0P1d3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = aiplatform.Model.list(filter=f'display_name=\"{model_display_name}\"')\n",
        "print(models)"
      ],
      "metadata": {
        "id": "ETxcIMJJ1TlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the ID of the model\n",
        "model_name = \"[your-model-resource-name]\"\n",
        "if model_name == \"[your-model-resource-name]\":\n",
        "    # Use the `resource_name` of the Model instance you created previously\n",
        "    model_name = model.resource_name\n",
        "    print(f\"Model name: {model_name}\")\n",
        "\n",
        "\n",
        "# Get a reference to the Model Service client\n",
        "client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
        "model_service_client = aiplatform.gapic.ModelServiceClient(\n",
        "    client_options=client_options\n",
        ")"
      ],
      "metadata": {
        "id": "vWf6Lp8O1kPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluations = model_service_client.list_model_evaluations(parent=model_name)\n",
        "model_evaluation = list(model_evaluations)[0]"
      ],
      "metadata": {
        "id": "r5z-o1PD1nFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_eval_dict = json_format.MessageToDict(model_evaluation._pb)\n",
        "metrics = model_eval_dict[\"metrics\"]\n",
        "confidence_metrics = metrics[\"confidenceMetrics\"]\n",
        "\n",
        "print(f'Area under precision-recall curve (AuPRC): {metrics[\"auPrc\"]}')\n",
        "for confidence_scores in confidence_metrics:\n",
        "    metrics = confidence_scores.keys()\n",
        "    print(\"\\n\")\n",
        "    for metric in metrics:\n",
        "        print(f\"\\t{metric}: {confidence_scores[metric]}\")"
      ],
      "metadata": {
        "id": "Yc0TgkiB1pZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy your text classification model**"
      ],
      "metadata": {
        "id": "VRt3BGiT1uqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployed_model_display_name = f\"e2e-deployed-text-classification-model-{TIMESTAMP}\"\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    deployed_model_display_name=deployed_model_display_name, sync=True\n",
        ")"
      ],
      "metadata": {
        "id": "zyJTnumz1smG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoints = aiplatform.Endpoint.list()\n",
        "\n",
        "endpoint_with_deployed_model = []\n",
        "\n",
        "for endpoint_ in endpoints:\n",
        "    for model in endpoint_.list_models():\n",
        "        if model.display_name.find(deployed_model_display_name) == 0:\n",
        "            endpoint_with_deployed_model.append(endpoint_)\n",
        "\n",
        "print(endpoint_with_deployed_model)"
      ],
      "metadata": {
        "id": "AIYGNu5K1zeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get online predictions from your model**"
      ],
      "metadata": {
        "id": "yVmkQ_RR132E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_name = \"[your-endpoint-name]\"\n",
        "if endpoint_name == \"[your-endpoint-name]\":\n",
        "    endpoint_name = endpoint.resource_name\n",
        "\n",
        "print(f\"Endpoint name: {endpoint_name}\")\n",
        "\n",
        "endpoint = aiplatform.Endpoint(endpoint_name)\n",
        "content = \"I got a high score on my math final!\"\n",
        "\n",
        "response = endpoint.predict(instances=[{\"content\": content}])\n",
        "\n",
        "for prediction_ in response.predictions:\n",
        "    ids = prediction_[\"ids\"]\n",
        "    display_names = prediction_[\"displayNames\"]\n",
        "    confidence_scores = prediction_[\"confidences\"]\n",
        "    for count, id in enumerate(ids):\n",
        "        print(f\"Prediction ID: {id}\")\n",
        "        print(f\"Prediction display name: {display_names[count]}\")\n",
        "        print(f\"Prediction confidence score: {confidence_scores[count]}\")"
      ],
      "metadata": {
        "id": "80pixZLr117L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get batch predictions from your model**"
      ],
      "metadata": {
        "id": "A4DlwCLb1-Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instances = [\n",
        "    \"We hiked through the woods and up the hill to the ice caves\",\n",
        "    \"My kitten is so cute\",\n",
        "]\n",
        "input_file_name = \"batch-prediction-input.jsonl\""
      ],
      "metadata": {
        "id": "UPf-DkPv18KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"[your-bucket-name]\"\n",
        "\n",
        "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"[your-bucket-name]\":\n",
        "    BUCKET_NAME = f\"automl-text-notebook-{TIMESTAMP}\"\n",
        "\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "\n",
        "! gsutil mb -l $REGION $BUCKET_URI"
      ],
      "metadata": {
        "id": "2xyDysy92EGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Storage client and create the new bucket\n",
        "storage = storage.Client()\n",
        "bucket = storage.bucket(BUCKET_NAME)\n",
        "\n",
        "# Iterate over the prediction instances, creating a new TXT file\n",
        "# for each.\n",
        "input_file_data = []\n",
        "for count, instance in enumerate(instances):\n",
        "    instance_name = f\"input_{count}.txt\"\n",
        "    instance_file_uri = f\"{BUCKET_URI}/{instance_name}\"\n",
        "\n",
        "    # Add the data to store in the JSONL input file.\n",
        "    tmp_data = {\"content\": instance_file_uri, \"mimeType\": \"text/plain\"}\n",
        "    input_file_data.append(tmp_data)\n",
        "\n",
        "    # Create the new instance file\n",
        "    blob = bucket.blob(instance_name)\n",
        "    blob.upload_from_string(instance)\n",
        "\n",
        "input_str = \"\\n\".join([str(d) for d in input_file_data])\n",
        "file_blob = bucket.blob(f\"{input_file_name}\")\n",
        "file_blob.upload_from_string(input_str)"
      ],
      "metadata": {
        "id": "rZnAshoL2HG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_display_name = \"e2e-text-classification-batch-prediction-job\"\n",
        "model = aiplatform.Model(model_name=model_name)\n",
        "\n",
        "batch_prediction_job = model.batch_predict(\n",
        "    job_display_name=job_display_name,\n",
        "    gcs_source=f\"{BUCKET_URI}/{input_file_name}\",\n",
        "    gcs_destination_prefix=f\"{BUCKET_URI}/output\",\n",
        "    sync=True,\n",
        ")\n",
        "\n",
        "batch_prediction_job_name = batch_prediction_job.resource_name"
      ],
      "metadata": {
        "id": "HMS-Spe_2KnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.aiplatform import jobs\n",
        "\n",
        "batch_job = jobs.BatchPredictionJob(batch_prediction_job_name)\n",
        "print(f\"Batch prediction job state: {str(batch_job.state)}\")"
      ],
      "metadata": {
        "id": "UUyr26R52NWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_OUTPUT = f\"{BUCKET_URI}/output\"\n",
        "\n",
        "! gsutil ls -a $BUCKET_OUTPUT"
      ],
      "metadata": {
        "id": "_9eU-c1G2P9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS_DIRECTORY = \"prediction_results\"\n",
        "RESULTS_DIRECTORY_FULL = f\"{RESULTS_DIRECTORY}/output\"\n",
        "\n",
        "# Create missing directories\n",
        "os.makedirs(RESULTS_DIRECTORY, exist_ok=True)\n",
        "\n",
        "# Get the Cloud Storage paths for each result\n",
        "! gsutil -m cp -r $BUCKET_OUTPUT $RESULTS_DIRECTORY\n",
        "\n",
        "# Get most recently modified directory\n",
        "latest_directory = max(\n",
        "    [\n",
        "        os.path.join(RESULTS_DIRECTORY_FULL, d)\n",
        "        for d in os.listdir(RESULTS_DIRECTORY_FULL)\n",
        "    ],\n",
        "    key=os.path.getmtime,\n",
        ")\n",
        "\n",
        "print(f\"Local results folder: {latest_directory}\")"
      ],
      "metadata": {
        "id": "aNci6qEf2Sig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get downloaded results in directory\n",
        "results_files = []\n",
        "for dirpath, _, files in os.walk(latest_directory):\n",
        "    for file in files:\n",
        "        if file.find(\"predictions\") >= 0:\n",
        "            results_files.append(os.path.join(dirpath, file))\n",
        "\n",
        "\n",
        "# Consolidate all the results into a list\n",
        "results = []\n",
        "for results_file in results_files:\n",
        "    # Open each result\n",
        "    with jsonlines.open(results_file) as reader:\n",
        "        for result in reader.iter(type=dict, skip_invalid=True):\n",
        "            instance = result[\"instance\"]\n",
        "            prediction = result[\"prediction\"]\n",
        "            print(f\"\\ninstance: {instance['content']}\")\n",
        "            for key, output in prediction.items():\n",
        "                print(f\"\\n{key}: {output}\")"
      ],
      "metadata": {
        "id": "V7IeRmo42VYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clean-up**"
      ],
      "metadata": {
        "id": "NYMJF53p2YO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil rm -r $BUCKET_URI\n",
        "\n",
        "batch_job.delete()\n",
        "\n",
        "# `force` parameter ensures that models are undeployed before deletion\n",
        "endpoint.delete(force=True)\n",
        "\n",
        "model.delete()\n",
        "\n",
        "text_dataset.delete()\n",
        "\n",
        "# Training job\n",
        "job.delete()"
      ],
      "metadata": {
        "id": "pMm1Z2_m2bCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}